{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta, date\n",
    "import pandas as pd\n",
    "import json\n",
    "import pymssql\n",
    "import os\n",
    "from configparser import ConfigParser\n",
    "import warnings\n",
    "from requests_oauthlib import OAuth2Session\n",
    "from oauthlib.oauth2 import BackendApplicationClient\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renovar_token(client_id, client_secret, token_url):\n",
    "    client = BackendApplicationClient(client_id=client_id)\n",
    "    oauth = OAuth2Session(client=client)\n",
    "    \n",
    "    # Obtém novo token\n",
    "    token = oauth.fetch_token(\n",
    "        token_url=token_url,\n",
    "        client_id=client_id,\n",
    "        client_secret=client_secret\n",
    "    )\n",
    "    \n",
    "    return token\n",
    "\n",
    "# Exemplo de uso\n",
    "token = renovar_token(\n",
    "    client_id='terceirizada',\n",
    "    client_secret='cf86507fdaf05a4f2cda151544513ae769bd305e',\n",
    "    token_url='https://terceirizada.api.nexti.com/security/oauth/token'\n",
    ")\n",
    "tokenaeon = token['access_token']\n",
    "\n",
    "# Exemplo de uso\n",
    "token = renovar_token(\n",
    "    client_id='provac',\n",
    "    client_secret='4e6b36b10798aaef19e5cb6ec88f295761c80236',\n",
    "    token_url='https://provac.api.nexti.com/security/oauth/token'\n",
    ")\n",
    "tokenprovac = token['access_token']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PONTO AEON\n",
    "\n",
    "#config_manager = ConfigManager()\n",
    "def obter_dados(start_date, end_date):\n",
    "\n",
    "  url = f\"https://terceirizada.api.nexti.com/clockings/start/{start_date}/finish/{end_date}\"\n",
    "\n",
    "  payload = {}\n",
    "  headers = {\n",
    "  'authorization': 'Bearer ' + tokenaeon\n",
    "  }\n",
    "\n",
    "  response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "  \n",
    "  return pd.DataFrame(response.json(), dtype=str)\n",
    "\n",
    "def format_date(date):\n",
    "    return date.strftime(\"%d%m%Y%H%M%S\")\n",
    "def obtem_segundos(data_hora_dimep, time_zone):\n",
    "    # Dicionário com os ajustes de fuso horário\n",
    "    fusos_horarios = {\n",
    "        \"America/Sao_Paulo\": -3,\n",
    "        \"AMERICA/PORTO_VELHO\": -4,\n",
    "        \"AMERICA/ARAGUAINA\": -3,\n",
    "        \"EUROPE/MADRID\": 2,\n",
    "        \"ATLANTIC/STANLEY\": -3,\n",
    "        \"AMERICA/BOGOTA\": -5,\n",
    "        \"EUROPE/LISBON\": 0,\n",
    "        \"AMERICA/LA_PAZ\": -4,\n",
    "        \"AMERICA/PORT_OF_SPAIN\": -4,\n",
    "        \"AMERICA/ARGENTINA/CORDOBA\": -3,\n",
    "        \"AMERICA/ARGENTINA/RIO_GALLEGOS\": -3,\n",
    "        \"AMERICA/ARGENTINA/TUCUMAN\": -3,\n",
    "        \"AMERICA/ARGENTINA/BUENOS_AIRES\": -3,\n",
    "        \"AMERICA/SANTIAGO\": -4,\n",
    "        \"AMERICA/GUAYAQUIL\": -5,\n",
    "        \"AMERICA/TEGUCIGALPA\": -6,\n",
    "        \"AMERICA/MERIDA\": -6,\n",
    "        \"AMERICA/MEXICO_CITY\": -6,\n",
    "        \"AMERICA/HERMOSILLO\": -7,\n",
    "        \"AMERICA/MANAGUA\": -6,\n",
    "        \"AMERICA/PANAMA\": -5,\n",
    "        \"AMERICA/ASUNCION\": -4,\n",
    "        \"AMERICA/LIMA\": -5,\n",
    "        \"AFRICA/JOHANNESBURG\": 2,\n",
    "        \"EUROPE/WARSAW\": 1,\n",
    "        \"AMERICA/SANTO_DOMINGO\": -4,\n",
    "        \"AMERICA/MONTERREY\": -6,\n",
    "        \"AMERICA/PORT-AU-PRINCE\": -5,\n",
    "        \"AMERICA/CHICAGO\": -6,\n",
    "        \"EUROPE/BERLIN\": 1,\n",
    "        \"EUROPE/AMSTERDAM\": 1,\n",
    "        \"AMERICA/MONTEVIDEO\": -3,\n",
    "        \"AMERICA/PHOENIX\": -7,\n",
    "        \"ASIA/AQTOBE\": 5\n",
    "    }\n",
    "\n",
    "    # Extrair a hora do registro\n",
    "    hora = int(data_hora_dimep[8:10])\n",
    "    minuto = int(data_hora_dimep[10:12])\n",
    "    \n",
    "    # Ajustar a hora de acordo com o fuso horário\n",
    "    ajuste = fusos_horarios.get(time_zone, 0)\n",
    "    hora_ajustada = hora + ajuste\n",
    "    \n",
    "    # Ajustar a data se necessário\n",
    "    if hora_ajustada < 0:\n",
    "        hora_ajustada += 24\n",
    "    elif hora_ajustada >= 24:\n",
    "        hora_ajustada -= 24\n",
    "    \n",
    "    # Calcular os segundos\n",
    "    segundos = (hora_ajustada * 3600) + (minuto * 60)\n",
    "    \n",
    "    return segundos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROVAC\n",
    "\n",
    "# PONTO DA PROVAC\n",
    "#config_manager = ConfigManager()\n",
    "def obter_dados_provac(start_date, end_date):\n",
    "\n",
    "  url = f\"https://provac.api.nexti.com/clockings/start/{start_date}/finish/{end_date}\"\n",
    "\n",
    "  payload = {}\n",
    "  headers = {\n",
    "  'Authorization': 'Bearer ' + tokenprovac\n",
    "    }\n",
    "\n",
    "  response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "  \n",
    "  return pd.DataFrame(response.json(), dtype=str)\n",
    "\n",
    "def format_date(date):\n",
    "    return date.strftime(\"%d%m%Y%H%M%S\")\n",
    "def obtem_segundos(data_hora_dimep, time_zone):\n",
    "    # Dicionário com os ajustes de fuso horário\n",
    "    fusos_horarios = {\n",
    "        \"America/Sao_Paulo\": -3,\n",
    "        \"AMERICA/PORTO_VELHO\": -4,\n",
    "        \"AMERICA/ARAGUAINA\": -3,\n",
    "        \"EUROPE/MADRID\": 2,\n",
    "        \"ATLANTIC/STANLEY\": -3,\n",
    "        \"AMERICA/BOGOTA\": -5,\n",
    "        \"EUROPE/LISBON\": 0,\n",
    "        \"AMERICA/LA_PAZ\": -4,\n",
    "        \"AMERICA/PORT_OF_SPAIN\": -4,\n",
    "        \"AMERICA/ARGENTINA/CORDOBA\": -3,\n",
    "        \"AMERICA/ARGENTINA/RIO_GALLEGOS\": -3,\n",
    "        \"AMERICA/ARGENTINA/TUCUMAN\": -3,\n",
    "        \"AMERICA/ARGENTINA/BUENOS_AIRES\": -3,\n",
    "        \"AMERICA/SANTIAGO\": -4,\n",
    "        \"AMERICA/GUAYAQUIL\": -5,\n",
    "        \"AMERICA/TEGUCIGALPA\": -6,\n",
    "        \"AMERICA/MERIDA\": -6,\n",
    "        \"AMERICA/MEXICO_CITY\": -6,\n",
    "        \"AMERICA/HERMOSILLO\": -7,\n",
    "        \"AMERICA/MANAGUA\": -6,\n",
    "        \"AMERICA/PANAMA\": -5,\n",
    "        \"AMERICA/ASUNCION\": -4,\n",
    "        \"AMERICA/LIMA\": -5,\n",
    "        \"AFRICA/JOHANNESBURG\": 2,\n",
    "        \"EUROPE/WARSAW\": 1,\n",
    "        \"AMERICA/SANTO_DOMINGO\": -4,\n",
    "        \"AMERICA/MONTERREY\": -6,\n",
    "        \"AMERICA/PORT-AU-PRINCE\": -5,\n",
    "        \"AMERICA/CHICAGO\": -6,\n",
    "        \"EUROPE/BERLIN\": 1,\n",
    "        \"EUROPE/AMSTERDAM\": 1,\n",
    "        \"AMERICA/MONTEVIDEO\": -3,\n",
    "        \"AMERICA/PHOENIX\": -7,\n",
    "        \"ASIA/AQTOBE\": 5\n",
    "    }\n",
    "\n",
    "    # Extrair a hora do registro\n",
    "    hora = int(data_hora_dimep[8:10])\n",
    "    minuto = int(data_hora_dimep[10:12])\n",
    "    \n",
    "    # Ajustar a hora de acordo com o fuso horário\n",
    "    ajuste = fusos_horarios.get(time_zone, 0)\n",
    "    hora_ajustada = hora + ajuste\n",
    "    \n",
    "    # Ajustar a data se necessário\n",
    "    if hora_ajustada < 0:\n",
    "        hora_ajustada += 24\n",
    "    elif hora_ajustada >= 24:\n",
    "        hora_ajustada -= 24\n",
    "    \n",
    "    # Calcular os segundos\n",
    "    segundos = (hora_ajustada * 3600) + (minuto * 60)\n",
    "    \n",
    "    return segundos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtem_data(data_hora_dimep):\n",
    "    \"\"\"\n",
    "    Converte a string de data do formato DDMMYYYY para um objeto de data Python.\n",
    "    \n",
    "    :param data_hora_dimep: String no formato 'DDMMYYYYhhmmss'\n",
    "    :return: Objeto datetime representando a data\n",
    "    \"\"\"\n",
    "    dia = data_hora_dimep[0:2]\n",
    "    mes = data_hora_dimep[2:4]\n",
    "    ano = data_hora_dimep[4:8]\n",
    "    \n",
    "    # Cria uma string de data no formato 'DD/MM/YYYY'\n",
    "    data_formatada = f\"{dia}/{mes}/{ano}\"\n",
    "    \n",
    "    # Converte a string para um objeto datetime\n",
    "    data_objeto = datetime.strptime(data_formatada, \"%d/%m/%Y\")\n",
    "    \n",
    "    return data_objeto.strftime(\"%Y%m%d\")\n",
    "\n",
    "def ajusta_id(item_id, tamanho_campo):\n",
    "    \"\"\"\n",
    "    Ajusta o ID para o tamanho do campo, removendo dígitos do início se necessário.\n",
    "    \n",
    "    :param item_id: O ID original (pode ser int ou str)\n",
    "    :param tamanho_campo: O tamanho máximo permitido para o campo\n",
    "    :return: O ID ajustado (como string)\n",
    "    \"\"\"\n",
    "    # Converte o ID para string\n",
    "    id_str = str(item_id)\n",
    "    \n",
    "    # Verifica se o comprimento do ID é maior que o tamanho do campo\n",
    "    if len(id_str) > tamanho_campo:\n",
    "        # Se for maior, pega os últimos dígitos\n",
    "        return id_str[-tamanho_campo:]\n",
    "    else:\n",
    "        # Se não for maior, retorna o ID original\n",
    "        return id_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-18 14:56:26.709250\n",
      "Data Inicial: 2024-11-21 00:00:00 e data ,final: 2024-11-21 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-11-22 00:00:00 e data ,final: 2024-11-22 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-11-23 00:00:00 e data ,final: 2024-11-23 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-11-24 00:00:00 e data ,final: 2024-11-24 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-11-25 00:00:00 e data ,final: 2024-11-25 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-11-26 00:00:00 e data ,final: 2024-11-26 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-11-27 00:00:00 e data ,final: 2024-11-27 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-11-28 00:00:00 e data ,final: 2024-11-28 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-11-29 00:00:00 e data ,final: 2024-11-29 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-11-30 00:00:00 e data ,final: 2024-11-30 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-12-01 00:00:00 e data ,final: 2024-12-01 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-12-02 00:00:00 e data ,final: 2024-12-02 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-12-03 00:00:00 e data ,final: 2024-12-03 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-12-04 00:00:00 e data ,final: 2024-12-04 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-12-05 00:00:00 e data ,final: 2024-12-05 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-12-06 00:00:00 e data ,final: 2024-12-06 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-12-07 00:00:00 e data ,final: 2024-12-07 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-12-08 00:00:00 e data ,final: 2024-12-08 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-12-09 00:00:00 e data ,final: 2024-12-09 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-12-10 00:00:00 e data ,final: 2024-12-10 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-12-11 00:00:00 e data ,final: 2024-12-11 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-12-12 00:00:00 e data ,final: 2024-12-12 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-12-13 00:00:00 e data ,final: 2024-12-13 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-12-14 00:00:00 e data ,final: 2024-12-14 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-12-15 00:00:00 e data ,final: 2024-12-15 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-12-16 00:00:00 e data ,final: 2024-12-16 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-12-17 00:00:00 e data ,final: 2024-12-17 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n",
      "Data Inicial: 2024-12-18 00:00:00 e data ,final: 2024-12-18 23:59:00\n",
      "Dados de clockings obtidos com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Data de hoje\n",
    "data_hoje = datetime.now()-timedelta(1)\n",
    "print(data_hoje)\n",
    "# Calculando o mês anterior\n",
    "mes_anterior = data_hoje.month - 1 if data_hoje.month > 1 else 12\n",
    "ano_anterior = data_hoje.year if data_hoje.month > 1 else data_hoje.year - 1\n",
    "\n",
    "# Data do dia 21 do mês anterior\n",
    "dia_21_mes_anterior = datetime(year=ano_anterior, month=mes_anterior, day=21)\n",
    "\n",
    "\n",
    "data = pd.date_range(dia_21_mes_anterior, data_hoje)\n",
    "\n",
    "dftt = pd.DataFrame()\n",
    "\n",
    "for dt in data:\n",
    "    # Define datas de início e fim\n",
    "    start_date = dt\n",
    "    end_date = datetime(dt.year, dt.month, dt.day, 23, 59, 0)\n",
    "    \n",
    "    print(f'Data Inicial: {start_date} e data ,final: {end_date}')\n",
    "    # Formata datas\n",
    "    formatted_start = format_date(start_date)\n",
    "    formatted_end = format_date(end_date)\n",
    "\n",
    "    # Obtém os dados de clockings\n",
    "    df = obter_dados(formatted_start, formatted_end)\n",
    "    df2 = obter_dados_provac(formatted_start, formatted_end)\n",
    "    \n",
    "    dftt = pd.concat([dftt, df, df2])\n",
    "\n",
    "    if dftt is not None:\n",
    "        print(\"Dados de clockings obtidos com sucesso.\")\n",
    "    else:\n",
    "        print(\"Falha ao obter os dados de clockings.\")\n",
    "\n",
    "novo_df = []\n",
    "for i, row in dftt.iterrows():\n",
    "    dData = obtem_data(row[\"clockingDate\"])\n",
    "    nSegundos = obtem_segundos(row[\"clockingDate\"], row[\"timezone\"])\n",
    "    cCodNSR = ajusta_id(row[\"id\"], 9)\n",
    "\n",
    "    novo_registro = [\n",
    "        row[\"id\"],                    # RR1_VALCON\n",
    "        row[\"personPIS\"],             # RR1_CODPIS\n",
    "        row[\"clockingCollectorName\"], # RR1_CODREL\n",
    "        row[\"clockingCollectorName\"], # RR1_CODREP\n",
    "        cCodNSR,                      # RR1_CODNSR\n",
    "        dData,                        # RR1_DATMAR\n",
    "        nSegundos,                    # RR1_NUMMAR\n",
    "        \"clockinmobile\",              # RR1_CODUNI\n",
    "        \"0\",                          # RR1_LOGIP\n",
    "        \"0\",                          # RR1_GEOFEN\n",
    "        \"99999999999\",                # RR1_CCTREP\n",
    "        0                             # RR1_VRSLAY\n",
    "    ]\n",
    "    \n",
    "    novo_df.append(novo_registro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um novo DataFrame com os dados processados\n",
    "resultado_df = pd.DataFrame(novo_df, columns=[\n",
    "    \"RR1_VALCON\", \"RR1_CODPIS\", \"RR1_CODREL\", \"RR1_CODREP\", \"RR1_CODNSR\", \n",
    "    \"RR1_DATMAR\", \"RR1_NUMMAR\", \"RR1_CODUNI\", \"RR1_LOGIP\", \"RR1_GEOFEN\", \n",
    "    \"RR1_CCTREP\", \"RR1_VRSLAY\"\n",
    "])\n",
    "# Verificar se PIS existe\n",
    "def conect_totvs():\n",
    "    serv = '192.168.0.236'\n",
    "    databa = 'PROTHEUS_PRODUCAO'\n",
    "    user = 'ismael.silva'\n",
    "    passa = 'w!1zayeUAM'\n",
    "    conn = pymssql.connect(serv, user, passa, databa)\n",
    "    cursor = conn.cursor(as_dict=True)\n",
    "    return conn, cursor\n",
    "\n",
    "con_tot, cursor = conect_totvs()\n",
    "query=\"\"\"\n",
    "SELECT \n",
    "    dbo.SRA010.RA_MAT, \n",
    "    dbo.SRA010.RA_NOME,\n",
    "    dbo.SRA010.R_E_C_N_O_ AS REGISTRO, \n",
    "    dbo.SRA010.RA_TNOTRAB, \n",
    "    dbo.SRA010.RA_PIS AS RR1_CODPIS\n",
    "FROM \n",
    "    dbo.SRA010\n",
    "WHERE \n",
    "  dbo.SRA010.RA_SITFOLH <> 'D' -- Assumindo que esta é a condição para \"não demitido\"\n",
    "  AND dbo.SRA010.D_E_L_E_T_<> '*'\n",
    "\"\"\"\n",
    "sra = pd.read_sql_query(query, con_tot, dtype=str)\n",
    "sra['RR1_CODPIS'] = sra['RR1_CODPIS'].str.strip()\n",
    "sra['existe'] = True\n",
    "resultado_df2 = pd.merge(resultado_df, sra[['RR1_CODPIS', 'existe']], how='left', on='RR1_CODPIS')\n",
    "\n",
    "\n",
    "# VERIFICA SE MARCAÇÃO EXISTE\n",
    "queryrr1=\"\"\"\n",
    "select \n",
    "    RR1_VALCON, \n",
    "    RR1_CODPIS, \n",
    "    'True' as Existe_marcacao\n",
    "from \n",
    "    RR1010 \n",
    "WHERE \n",
    "    D_E_L_E_T_ <> '*'\n",
    "\"\"\"\n",
    "rr1 = pd.read_sql_query(queryrr1, con_tot, dtype=str)\n",
    "rr1['RR1_VALCON'] = rr1['RR1_VALCON'].str.replace('.0', '')\n",
    "resultado_df3 = pd.merge(resultado_df2, rr1, how='left', on='RR1_VALCON')\n",
    "dfMarcacao = resultado_df3[(resultado_df3['existe']==True)&(resultado_df3['RR1_CODPIS_y'].isnull())]\n",
    "dfMarcacao.drop(columns={'RR1_CODPIS_y'}, inplace=True)\n",
    "dfMarcacao.rename(columns={'RR1_CODPIS_x':'RR1_CODPIS'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de Marcação pendente\n",
      "RR1_DATMAR\n",
      "20241121      2\n",
      "20241122      1\n",
      "20241127      2\n",
      "20241128      2\n",
      "20241129      2\n",
      "20241203      1\n",
      "20241204      5\n",
      "20241205      2\n",
      "20241206      4\n",
      "20241209     11\n",
      "20241210     12\n",
      "20241211     18\n",
      "20241212     48\n",
      "20241213    171\n",
      "20241214      6\n",
      "20241215      2\n",
      "20241216    158\n",
      "20241217    152\n",
      "20241218    100\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Quantidade de Marcação pendente')\n",
    "print(dfMarcacao.groupby('RR1_DATMAR').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_maior_recno(cursor):\n",
    "    query = \"SELECT MAX(R_E_C_N_O_) as max_recno FROM RR1010\"\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchone()\n",
    "    return result['max_recno'] if result['max_recno'] is not None else 0\n",
    "\n",
    "def inserir_marcacoes(df_marcacoes, cursor, conn):\n",
    "    maior_recno = obter_maior_recno(cursor)\n",
    "    \n",
    "    for _, row in df_marcacoes.iterrows():\n",
    "        maior_recno += 1\n",
    "        query = \"\"\"\n",
    "        INSERT INTO RR1010 (\n",
    "            RR1_VALCON, RR1_CODPIS, RR1_CODREL, RR1_CODREP, RR1_CODNSR, \n",
    "            RR1_DATMAR, RR1_NUMMAR, RR1_CODUNI, RR1_LOGIP, RR1_GEOFEN, \n",
    "            RR1_CCTREP, RR1_VRSLAY, R_E_C_N_O_\n",
    "        ) VALUES (\n",
    "            %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s\n",
    "        )\n",
    "        \"\"\"\n",
    "        values = (\n",
    "            row['RR1_VALCON'], row['RR1_CODPIS'], row['RR1_CODREL'], row['RR1_CODREP'],\n",
    "            row['RR1_CODNSR'], row['RR1_DATMAR'], row['RR1_NUMMAR'], row['RR1_CODUNI'],\n",
    "            row['RR1_LOGIP'], row['RR1_GEOFEN'], row['RR1_CCTREP'], row['RR1_VRSLAY'],\n",
    "            maior_recno\n",
    "        )\n",
    "        try:\n",
    "            cursor.execute(query, values)\n",
    "            conn.commit()\n",
    "            print(f\"Marcação inserida com sucesso: {row['RR1_VALCON']} (R_E_C_N_O_: {maior_recno})\")\n",
    "        except Exception as e:\n",
    "            conn.rollback()\n",
    "            print(f\"Erro ao inserir marcação {row['RR1_VALCON']}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso da função\n",
    "try:\n",
    "    con_tot, cursor = conect_totvs()\n",
    "    inserir_marcacoes(dfMarcacao, cursor, con_tot)\n",
    "finally:\n",
    "    cursor.close()\n",
    "    con_tot.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
